{
  "A": [
    {
      "type": "A",
      "path": "models/2025-12-30_16-10-47/LORA/YEARS/topk_lora_experiment/rank16-k2-sc20-Qwen_Qwen2.5-3B-Instruct-rc0.001-lr4e-07-epochs6",
      "timestamp": "2025-12-30T16:43:49.387757+00:00",
      "run_name": "2025-12-30_16-10-47",
      "method": "LORA",
      "dataset": "YEARS",
      "project": "topk_lora_experiment",
      "model_id": "Qwen/Qwen2.5-3B-Instruct",
      "lr": 4e-07,
      "epochs": 6,
      "retain_coeff": 0.001,
      "lora_rank": 16,
      "steering_coeff": 20,
      "lora_layer_budget_k": 2,
      "selected_blocks": [
        19,
        28
      ],
      "final_gate_scores": [
        -0.019505245611071587,
        -0.0006054528057575226,
        -0.0033960219006985426,
        -0.003197832964360714,
        0.013436204753816128,
        0.009931203909218311,
        -0.013681450858712196,
        -0.0018512606620788574,
        0.011702020652592182,
        -0.0066699255257844925,
        0.0038559262175112963,
        -0.006804247852414846,
        -0.0028729941695928574,
        0.013557206839323044,
        -0.003376457840204239,
        0.0007657092646695673,
        -0.009699399583041668,
        -0.002514604013413191,
        0.005064564757049084,
        0.018284006044268608,
        0.005606777034699917,
        -0.0044800820760428905,
        0.009764302521944046,
        -0.009085980243980885,
        0.008494921959936619,
        0.0006475340924225748,
        -0.007643502671271563,
        0.008422628045082092,
        0.01608669012784958,
        0.006973529700189829,
        -0.008992253802716732,
        -0.019795246422290802,
        0.010861153714358807,
        0.00852845050394535,
        0.0027102651074528694,
        -0.011970738880336285
      ],
      "gate_tau_start": 10.0,
      "gate_tau_end": 0.1,
      "gate_seed": 4,
      "forget_accs": {
        "data/dates-years-trimmed/split_0.jsonl": {
          "0": 0.6265822784810127
        },
        "data/dates-years-trimmed/split_1.jsonl": {
          "0": 0.6012658227848101
        },
        "data/dates-years-trimmed/split_2.jsonl": {
          "0": 0.6329113924050633
        },
        "data/dates-years-trimmed/split_3.jsonl": {
          "0": 0.6392405063291139
        },
        "data/dates-years-trimmed/split_4.jsonl": {
          "0": 0.6815286624203821
        }
      },
      "forget_accs_calibrated": {
        "data/dates-years-trimmed/split_0.jsonl": {
          "0": 0.5822784900665283
        },
        "data/dates-years-trimmed/split_1.jsonl": {
          "0": 0.5759493708610535
        },
        "data/dates-years-trimmed/split_2.jsonl": {
          "0": 0.6265822649002075
        },
        "data/dates-years-trimmed/split_3.jsonl": {
          "0": 0.6582278609275818
        },
        "data/dates-years-trimmed/split_4.jsonl": {
          "0": 0.6815286874771118
        }
      },
      "retain_accs": {
        "data/mmlu_cats_random_trimmed/mmlu_health.jsonl": {
          "0": 0.732484076433121
        },
        "data/mmlu_cats_random_trimmed/mmlu_history.jsonl": {
          "0": 0.8280254777070064
        },
        "data/mmlu_cats_random_trimmed/mmlu_law.jsonl": {
          "0": 0.49044585987261147
        },
        "data/mmlu_cats_random_trimmed/mmlu_philosophy.jsonl": {
          "0": 0.5859872611464968
        },
        "data/mmlu_cats_random_trimmed/mmlu_social sciences.jsonl": {
          "0": 0.7261146496815286
        }
      },
      "retain_accs_calibrated": {
        "data/mmlu_cats_random_trimmed/mmlu_health.jsonl": {
          "0": 0.7324841022491455
        },
        "data/mmlu_cats_random_trimmed/mmlu_history.jsonl": {
          "0": 0.8152866363525391
        },
        "data/mmlu_cats_random_trimmed/mmlu_law.jsonl": {
          "0": 0.4904458522796631
        },
        "data/mmlu_cats_random_trimmed/mmlu_philosophy.jsonl": {
          "0": 0.5286624431610107
        },
        "data/mmlu_cats_random_trimmed/mmlu_social sciences.jsonl": {
          "0": 0.7515923976898193
        }
      },
      "retain_accs_5_shot": {},
      "retain_accs_5_shot_calibrated": {}
    },
    {
      "type": "A",
      "path": "models/2025-12-30_16-10-47/LORA/YEARS/topk_lora_experiment/rank16-k12-sc20-Qwen_Qwen2.5-3B-Instruct-rc0.001-lr4e-07-epochs6",
      "timestamp": "2025-12-30T17:18:32.060208+00:00",
      "run_name": "2025-12-30_16-10-47",
      "method": "LORA",
      "dataset": "YEARS",
      "project": "topk_lora_experiment",
      "model_id": "Qwen/Qwen2.5-3B-Instruct",
      "lr": 4e-07,
      "epochs": 6,
      "retain_coeff": 0.001,
      "lora_rank": 16,
      "steering_coeff": 20,
      "lora_layer_budget_k": 12,
      "selected_blocks": [
        19,
        28,
        13,
        4,
        8,
        32,
        5,
        22,
        33,
        24,
        27,
        29
      ],
      "final_gate_scores": [
        -0.019505245611071587,
        -0.0006054528057575226,
        -0.0033960219006985426,
        -0.003197832964360714,
        0.013436204753816128,
        0.009931203909218311,
        -0.013681450858712196,
        -0.0018512606620788574,
        0.011702020652592182,
        -0.0066699255257844925,
        0.0038559262175112963,
        -0.006804247852414846,
        -0.0028729941695928574,
        0.013557206839323044,
        -0.003376457840204239,
        0.0007657092646695673,
        -0.009699399583041668,
        -0.002514604013413191,
        0.005064564757049084,
        0.018284006044268608,
        0.005606777034699917,
        -0.0044800820760428905,
        0.009764302521944046,
        -0.009085980243980885,
        0.008494921959936619,
        0.0006475340924225748,
        -0.007643502671271563,
        0.008422628045082092,
        0.01608669012784958,
        0.006973529700189829,
        -0.008992253802716732,
        -0.019795246422290802,
        0.010861153714358807,
        0.00852845050394535,
        0.0027102651074528694,
        -0.011970738880336285
      ],
      "gate_tau_start": 10.0,
      "gate_tau_end": 0.1,
      "gate_seed": 4,
      "forget_accs": {
        "data/dates-years-trimmed/split_0.jsonl": {
          "0": 0.6265822784810127
        },
        "data/dates-years-trimmed/split_1.jsonl": {
          "0": 0.6012658227848101
        },
        "data/dates-years-trimmed/split_2.jsonl": {
          "0": 0.6329113924050633
        },
        "data/dates-years-trimmed/split_3.jsonl": {
          "0": 0.6265822784810127
        },
        "data/dates-years-trimmed/split_4.jsonl": {
          "0": 0.6751592356687898
        }
      },
      "forget_accs_calibrated": {
        "data/dates-years-trimmed/split_0.jsonl": {
          "0": 0.5822784900665283
        },
        "data/dates-years-trimmed/split_1.jsonl": {
          "0": 0.5759493708610535
        },
        "data/dates-years-trimmed/split_2.jsonl": {
          "0": 0.6202532052993774
        },
        "data/dates-years-trimmed/split_3.jsonl": {
          "0": 0.6582278609275818
        },
        "data/dates-years-trimmed/split_4.jsonl": {
          "0": 0.6815286874771118
        }
      },
      "retain_accs": {
        "data/mmlu_cats_random_trimmed/mmlu_health.jsonl": {
          "0": 0.732484076433121
        },
        "data/mmlu_cats_random_trimmed/mmlu_history.jsonl": {
          "0": 0.8089171974522293
        },
        "data/mmlu_cats_random_trimmed/mmlu_law.jsonl": {
          "0": 0.4840764331210191
        },
        "data/mmlu_cats_random_trimmed/mmlu_philosophy.jsonl": {
          "0": 0.5859872611464968
        },
        "data/mmlu_cats_random_trimmed/mmlu_social sciences.jsonl": {
          "0": 0.732484076433121
        }
      },
      "retain_accs_calibrated": {
        "data/mmlu_cats_random_trimmed/mmlu_health.jsonl": {
          "0": 0.7261146306991577
        },
        "data/mmlu_cats_random_trimmed/mmlu_history.jsonl": {
          "0": 0.8152866363525391
        },
        "data/mmlu_cats_random_trimmed/mmlu_law.jsonl": {
          "0": 0.4968152940273285
        },
        "data/mmlu_cats_random_trimmed/mmlu_philosophy.jsonl": {
          "0": 0.5286624431610107
        },
        "data/mmlu_cats_random_trimmed/mmlu_social sciences.jsonl": {
          "0": 0.7579618096351624
        }
      },
      "retain_accs_5_shot": {},
      "retain_accs_5_shot_calibrated": {}
    },
    {
      "type": "A",
      "path": "models/2025-12-30_16-10-47/LORA/YEARS/topk_lora_experiment/rank16-k6-sc20-Qwen_Qwen2.5-3B-Instruct-rc0.001-lr4e-07-epochs6",
      "timestamp": "2025-12-30T17:50:38.118602+00:00",
      "run_name": "2025-12-30_16-10-47",
      "method": "LORA",
      "dataset": "YEARS",
      "project": "topk_lora_experiment",
      "model_id": "Qwen/Qwen2.5-3B-Instruct",
      "lr": 4e-07,
      "epochs": 6,
      "retain_coeff": 0.001,
      "lora_rank": 16,
      "steering_coeff": 20,
      "lora_layer_budget_k": 6,
      "selected_blocks": [
        19,
        28,
        13,
        4,
        8,
        32
      ],
      "final_gate_scores": [
        -0.019505245611071587,
        -0.0006054528057575226,
        -0.0033960219006985426,
        -0.003197832964360714,
        0.013436204753816128,
        0.009931203909218311,
        -0.013681450858712196,
        -0.0018512606620788574,
        0.011702020652592182,
        -0.0066699255257844925,
        0.0038559262175112963,
        -0.006804247852414846,
        -0.0028729941695928574,
        0.013557206839323044,
        -0.003376457840204239,
        0.0007657092646695673,
        -0.009699399583041668,
        -0.002514604013413191,
        0.005064564757049084,
        0.018284006044268608,
        0.005606777034699917,
        -0.0044800820760428905,
        0.009764302521944046,
        -0.009085980243980885,
        0.008494921959936619,
        0.0006475340924225748,
        -0.007643502671271563,
        0.008422628045082092,
        0.01608669012784958,
        0.006973529700189829,
        -0.008992253802716732,
        -0.019795246422290802,
        0.010861153714358807,
        0.00852845050394535,
        0.0027102651074528694,
        -0.011970738880336285
      ],
      "gate_tau_start": 10.0,
      "gate_tau_end": 0.1,
      "gate_seed": 4,
      "forget_accs": {
        "data/dates-years-trimmed/split_0.jsonl": {
          "0": 0.6265822784810127
        },
        "data/dates-years-trimmed/split_1.jsonl": {
          "0": 0.6012658227848101
        },
        "data/dates-years-trimmed/split_2.jsonl": {
          "0": 0.6329113924050633
        },
        "data/dates-years-trimmed/split_3.jsonl": {
          "0": 0.6265822784810127
        },
        "data/dates-years-trimmed/split_4.jsonl": {
          "0": 0.6751592356687898
        }
      },
      "forget_accs_calibrated": {
        "data/dates-years-trimmed/split_0.jsonl": {
          "0": 0.5822784900665283
        },
        "data/dates-years-trimmed/split_1.jsonl": {
          "0": 0.5759493708610535
        },
        "data/dates-years-trimmed/split_2.jsonl": {
          "0": 0.6265822649002075
        },
        "data/dates-years-trimmed/split_3.jsonl": {
          "0": 0.6582278609275818
        },
        "data/dates-years-trimmed/split_4.jsonl": {
          "0": 0.668789803981781
        }
      },
      "retain_accs": {
        "data/mmlu_cats_random_trimmed/mmlu_health.jsonl": {
          "0": 0.732484076433121
        },
        "data/mmlu_cats_random_trimmed/mmlu_history.jsonl": {
          "0": 0.8152866242038217
        },
        "data/mmlu_cats_random_trimmed/mmlu_law.jsonl": {
          "0": 0.49044585987261147
        },
        "data/mmlu_cats_random_trimmed/mmlu_philosophy.jsonl": {
          "0": 0.5796178343949044
        },
        "data/mmlu_cats_random_trimmed/mmlu_social sciences.jsonl": {
          "0": 0.732484076433121
        }
      },
      "retain_accs_calibrated": {
        "data/mmlu_cats_random_trimmed/mmlu_health.jsonl": {
          "0": 0.7261146306991577
        },
        "data/mmlu_cats_random_trimmed/mmlu_history.jsonl": {
          "0": 0.8152866363525391
        },
        "data/mmlu_cats_random_trimmed/mmlu_law.jsonl": {
          "0": 0.5031847357749939
        },
        "data/mmlu_cats_random_trimmed/mmlu_philosophy.jsonl": {
          "0": 0.5159235596656799
        },
        "data/mmlu_cats_random_trimmed/mmlu_social sciences.jsonl": {
          "0": 0.7515923976898193
        }
      },
      "retain_accs_5_shot": {},
      "retain_accs_5_shot_calibrated": {}
    },
    {
      "type": "A",
      "path": "models/2025-12-30_16-10-47/LORA/YEARS/topk_lora_experiment/rank16-k18-sc20-Qwen_Qwen2.5-3B-Instruct-rc0.001-lr4e-07-epochs6",
      "timestamp": "2025-12-30T18:23:06.104379+00:00",
      "run_name": "2025-12-30_16-10-47",
      "method": "LORA",
      "dataset": "YEARS",
      "project": "topk_lora_experiment",
      "model_id": "Qwen/Qwen2.5-3B-Instruct",
      "lr": 4e-07,
      "epochs": 6,
      "retain_coeff": 0.001,
      "lora_rank": 16,
      "steering_coeff": 20,
      "lora_layer_budget_k": 18,
      "selected_blocks": [
        19,
        28,
        13,
        4,
        8,
        32,
        5,
        22,
        33,
        24,
        27,
        29,
        20,
        18,
        10,
        34,
        15,
        25
      ],
      "final_gate_scores": [
        -0.019505245611071587,
        -0.0006054528057575226,
        -0.0033960219006985426,
        -0.003197832964360714,
        0.013436204753816128,
        0.009931203909218311,
        -0.013681450858712196,
        -0.0018512606620788574,
        0.011702020652592182,
        -0.0066699255257844925,
        0.0038559262175112963,
        -0.006804247852414846,
        -0.0028729941695928574,
        0.013557206839323044,
        -0.003376457840204239,
        0.0007657092646695673,
        -0.009699399583041668,
        -0.002514604013413191,
        0.005064564757049084,
        0.018284006044268608,
        0.005606777034699917,
        -0.0044800820760428905,
        0.009764302521944046,
        -0.009085980243980885,
        0.008494921959936619,
        0.0006475340924225748,
        -0.007643502671271563,
        0.008422628045082092,
        0.01608669012784958,
        0.006973529700189829,
        -0.008992253802716732,
        -0.019795246422290802,
        0.010861153714358807,
        0.00852845050394535,
        0.0027102651074528694,
        -0.011970738880336285
      ],
      "gate_tau_start": 10.0,
      "gate_tau_end": 0.1,
      "gate_seed": 4,
      "forget_accs": {
        "data/dates-years-trimmed/split_0.jsonl": {
          "0": 0.6265822784810127
        },
        "data/dates-years-trimmed/split_1.jsonl": {
          "0": 0.6012658227848101
        },
        "data/dates-years-trimmed/split_2.jsonl": {
          "0": 0.6329113924050633
        },
        "data/dates-years-trimmed/split_3.jsonl": {
          "0": 0.6455696202531646
        },
        "data/dates-years-trimmed/split_4.jsonl": {
          "0": 0.6878980891719745
        }
      },
      "forget_accs_calibrated": {
        "data/dates-years-trimmed/split_0.jsonl": {
          "0": 0.5886076092720032
        },
        "data/dates-years-trimmed/split_1.jsonl": {
          "0": 0.5822784900665283
        },
        "data/dates-years-trimmed/split_2.jsonl": {
          "0": 0.6202532052993774
        },
        "data/dates-years-trimmed/split_3.jsonl": {
          "0": 0.6582278609275818
        },
        "data/dates-years-trimmed/split_4.jsonl": {
          "0": 0.6815286874771118
        }
      },
      "retain_accs": {
        "data/mmlu_cats_random_trimmed/mmlu_health.jsonl": {
          "0": 0.732484076433121
        },
        "data/mmlu_cats_random_trimmed/mmlu_history.jsonl": {
          "0": 0.8089171974522293
        },
        "data/mmlu_cats_random_trimmed/mmlu_law.jsonl": {
          "0": 0.49044585987261147
        },
        "data/mmlu_cats_random_trimmed/mmlu_philosophy.jsonl": {
          "0": 0.5923566878980892
        },
        "data/mmlu_cats_random_trimmed/mmlu_social sciences.jsonl": {
          "0": 0.732484076433121
        }
      },
      "retain_accs_calibrated": {
        "data/mmlu_cats_random_trimmed/mmlu_health.jsonl": {
          "0": 0.7388535141944885
        },
        "data/mmlu_cats_random_trimmed/mmlu_history.jsonl": {
          "0": 0.8152866363525391
        },
        "data/mmlu_cats_random_trimmed/mmlu_law.jsonl": {
          "0": 0.48407644033432007
        },
        "data/mmlu_cats_random_trimmed/mmlu_philosophy.jsonl": {
          "0": 0.522292971611023
        },
        "data/mmlu_cats_random_trimmed/mmlu_social sciences.jsonl": {
          "0": 0.7515923976898193
        }
      },
      "retain_accs_5_shot": {},
      "retain_accs_5_shot_calibrated": {}
    },
    {
      "type": "A",
      "path": "models/2025-12-30_16-10-47/LORA/YEARS/topk_lora_experiment/rank16-k24-sc20-Qwen_Qwen2.5-3B-Instruct-rc0.001-lr4e-07-epochs6",
      "timestamp": "2025-12-30T18:58:18.126693+00:00",
      "run_name": "2025-12-30_16-10-47",
      "method": "LORA",
      "dataset": "YEARS",
      "project": "topk_lora_experiment",
      "model_id": "Qwen/Qwen2.5-3B-Instruct",
      "lr": 4e-07,
      "epochs": 6,
      "retain_coeff": 0.001,
      "lora_rank": 16,
      "steering_coeff": 20,
      "lora_layer_budget_k": 24,
      "selected_blocks": [
        19,
        28,
        13,
        4,
        8,
        32,
        5,
        22,
        33,
        24,
        27,
        29,
        20,
        18,
        10,
        34,
        15,
        25,
        1,
        7,
        17,
        12,
        3,
        14
      ],
      "final_gate_scores": [
        -0.019505245611071587,
        -0.0006054528057575226,
        -0.0033960219006985426,
        -0.003197832964360714,
        0.013436204753816128,
        0.009931203909218311,
        -0.013681450858712196,
        -0.0018512606620788574,
        0.011702020652592182,
        -0.0066699255257844925,
        0.0038559262175112963,
        -0.006804247852414846,
        -0.0028729941695928574,
        0.013557206839323044,
        -0.003376457840204239,
        0.0007657092646695673,
        -0.009699399583041668,
        -0.002514604013413191,
        0.005064564757049084,
        0.018284006044268608,
        0.005606777034699917,
        -0.0044800820760428905,
        0.009764302521944046,
        -0.009085980243980885,
        0.008494921959936619,
        0.0006475340924225748,
        -0.007643502671271563,
        0.008422628045082092,
        0.01608669012784958,
        0.006973529700189829,
        -0.008992253802716732,
        -0.019795246422290802,
        0.010861153714358807,
        0.00852845050394535,
        0.0027102651074528694,
        -0.011970738880336285
      ],
      "gate_tau_start": 10.0,
      "gate_tau_end": 0.1,
      "gate_seed": 4,
      "forget_accs": {
        "data/dates-years-trimmed/split_0.jsonl": {
          "0": 0.6329113924050633
        },
        "data/dates-years-trimmed/split_1.jsonl": {
          "0": 0.6012658227848101
        },
        "data/dates-years-trimmed/split_2.jsonl": {
          "0": 0.6392405063291139
        },
        "data/dates-years-trimmed/split_3.jsonl": {
          "0": 0.6518987341772152
        },
        "data/dates-years-trimmed/split_4.jsonl": {
          "0": 0.6878980891719745
        }
      },
      "forget_accs_calibrated": {
        "data/dates-years-trimmed/split_0.jsonl": {
          "0": 0.594936728477478
        },
        "data/dates-years-trimmed/split_1.jsonl": {
          "0": 0.5696202516555786
        },
        "data/dates-years-trimmed/split_2.jsonl": {
          "0": 0.6265822649002075
        },
        "data/dates-years-trimmed/split_3.jsonl": {
          "0": 0.6582278609275818
        },
        "data/dates-years-trimmed/split_4.jsonl": {
          "0": 0.675159215927124
        }
      },
      "retain_accs": {
        "data/mmlu_cats_random_trimmed/mmlu_health.jsonl": {
          "0": 0.732484076433121
        },
        "data/mmlu_cats_random_trimmed/mmlu_history.jsonl": {
          "0": 0.8152866242038217
        },
        "data/mmlu_cats_random_trimmed/mmlu_law.jsonl": {
          "0": 0.4713375796178344
        },
        "data/mmlu_cats_random_trimmed/mmlu_philosophy.jsonl": {
          "0": 0.5923566878980892
        },
        "data/mmlu_cats_random_trimmed/mmlu_social sciences.jsonl": {
          "0": 0.732484076433121
        }
      },
      "retain_accs_calibrated": {
        "data/mmlu_cats_random_trimmed/mmlu_health.jsonl": {
          "0": 0.7324841022491455
        },
        "data/mmlu_cats_random_trimmed/mmlu_history.jsonl": {
          "0": 0.8216560482978821
        },
        "data/mmlu_cats_random_trimmed/mmlu_law.jsonl": {
          "0": 0.4904458522796631
        },
        "data/mmlu_cats_random_trimmed/mmlu_philosophy.jsonl": {
          "0": 0.5414012670516968
        },
        "data/mmlu_cats_random_trimmed/mmlu_social sciences.jsonl": {
          "0": 0.7452229261398315
        }
      },
      "retain_accs_5_shot": {},
      "retain_accs_5_shot_calibrated": {}
    }
  ],
  "B": [
    {
      "type": "B",
      "path": "models/2025-12-30_16-10-47/fted/LORA/YEARS/topk_lora_experiment/rank16-k2-sc20-Qwen_Qwen2.5-3B-Instruct-rc0.001-lr4e-07-epochs6/topk_lora_experiment/LossType.QUESTION_LETTER_ANSWER/ft-skip_split4/lr1e-06-epoch2-epoch2",
      "timestamp": "2025-12-30T16:46:25.802606+00:00",
      "run_name": "2025-12-30_16-10-47",
      "method": "LORA",
      "dataset": "YEARS",
      "project": "topk_lora_experiment",
      "model_id": "Qwen/Qwen2.5-3B-Instruct",
      "lr": 1e-06,
      "epochs": 2,
      "retain_coeff": 0.001,
      "lora_rank": 16,
      "steering_coeff": 20,
      "lora_layer_budget_k": 2,
      "selected_blocks": [
        19,
        28
      ],
      "final_gate_scores": [
        -0.019505245611071587,
        -0.0006054528057575226,
        -0.0033960219006985426,
        -0.003197832964360714,
        0.013436204753816128,
        0.009931203909218311,
        -0.013681450858712196,
        -0.0018512606620788574,
        0.011702020652592182,
        -0.0066699255257844925,
        0.0038559262175112963,
        -0.006804247852414846,
        -0.0028729941695928574,
        0.013557206839323044,
        -0.003376457840204239,
        0.0007657092646695673,
        -0.009699399583041668,
        -0.002514604013413191,
        0.005064564757049084,
        0.018284006044268608,
        0.005606777034699917,
        -0.0044800820760428905,
        0.009764302521944046,
        -0.009085980243980885,
        0.008494921959936619,
        0.0006475340924225748,
        -0.007643502671271563,
        0.008422628045082092,
        0.01608669012784958,
        0.006973529700189829,
        -0.008992253802716732,
        -0.019795246422290802,
        0.010861153714358807,
        0.00852845050394535,
        0.0027102651074528694,
        -0.011970738880336285
      ],
      "gate_tau_start": 10.0,
      "gate_tau_end": 0.1,
      "gate_seed": 4,
      "a_path": "models/2025-12-30_16-10-47/LORA/YEARS/topk_lora_experiment/rank16-k2-sc20-Qwen_Qwen2.5-3B-Instruct-rc0.001-lr4e-07-epochs6",
      "a_lr": 4e-07,
      "a_epochs": 6,
      "loss_type": "QUESTION_LETTER_ANSWER",
      "skip_split": 4,
      "forget_accs": {
        "data/dates-years-trimmed/split_0.jsonl": {
          "0": 0.6645569620253164
        },
        "data/dates-years-trimmed/split_1.jsonl": {
          "0": 0.7025316455696202
        },
        "data/dates-years-trimmed/split_2.jsonl": {
          "0": 0.7025316455696202
        },
        "data/dates-years-trimmed/split_3.jsonl": {
          "0": 0.7088607594936709
        },
        "data/dates-years-trimmed/split_4.jsonl": {
          "0": 0.6942675159235668
        }
      },
      "forget_accs_calibrated": {
        "data/dates-years-trimmed/split_0.jsonl": {
          "0": 0.6708860993385315
        },
        "data/dates-years-trimmed/split_1.jsonl": {
          "0": 0.689873456954956
        },
        "data/dates-years-trimmed/split_2.jsonl": {
          "0": 0.6835443377494812
        },
        "data/dates-years-trimmed/split_3.jsonl": {
          "0": 0.702531635761261
        },
        "data/dates-years-trimmed/split_4.jsonl": {
          "0": 0.675159215927124
        }
      },
      "retain_accs": {
        "data/mmlu_cats_random_trimmed/mmlu_health.jsonl": {
          "0": 0.7197452229299363
        },
        "data/mmlu_cats_random_trimmed/mmlu_history.jsonl": {
          "0": 0.7898089171974523
        },
        "data/mmlu_cats_random_trimmed/mmlu_law.jsonl": {
          "0": 0.4968152866242038
        },
        "data/mmlu_cats_random_trimmed/mmlu_philosophy.jsonl": {
          "0": 0.5859872611464968
        },
        "data/mmlu_cats_random_trimmed/mmlu_social sciences.jsonl": {
          "0": 0.7197452229299363
        }
      },
      "retain_accs_calibrated": {
        "data/mmlu_cats_random_trimmed/mmlu_health.jsonl": {
          "0": 0.7388535141944885
        },
        "data/mmlu_cats_random_trimmed/mmlu_history.jsonl": {
          "0": 0.802547812461853
        },
        "data/mmlu_cats_random_trimmed/mmlu_law.jsonl": {
          "0": 0.5031847357749939
        },
        "data/mmlu_cats_random_trimmed/mmlu_philosophy.jsonl": {
          "0": 0.5286624431610107
        },
        "data/mmlu_cats_random_trimmed/mmlu_social sciences.jsonl": {
          "0": 0.7579618096351624
        }
      },
      "retain_accs_5_shot": {},
      "retain_accs_5_shot_calibrated": {}
    },
    {
      "type": "B",
      "path": "models/2025-12-30_16-10-47/fted/LORA/YEARS/topk_lora_experiment/rank16-k6-sc20-Qwen_Qwen2.5-3B-Instruct-rc0.001-lr4e-07-epochs6/topk_lora_experiment/LossType.QUESTION_LETTER_ANSWER/ft-skip_split4/lr1e-06-epoch2-epoch2",
      "timestamp": "2025-12-30T18:24:30.523380+00:00",
      "run_name": "2025-12-30_16-10-47",
      "method": "LORA",
      "dataset": "YEARS",
      "project": "topk_lora_experiment",
      "model_id": "Qwen/Qwen2.5-3B-Instruct",
      "lr": 1e-06,
      "epochs": 2,
      "retain_coeff": 0.001,
      "lora_rank": 16,
      "steering_coeff": 20,
      "lora_layer_budget_k": 6,
      "selected_blocks": [
        19,
        28,
        13,
        4,
        8,
        32
      ],
      "final_gate_scores": [
        -0.019505245611071587,
        -0.0006054528057575226,
        -0.0033960219006985426,
        -0.003197832964360714,
        0.013436204753816128,
        0.009931203909218311,
        -0.013681450858712196,
        -0.0018512606620788574,
        0.011702020652592182,
        -0.0066699255257844925,
        0.0038559262175112963,
        -0.006804247852414846,
        -0.0028729941695928574,
        0.013557206839323044,
        -0.003376457840204239,
        0.0007657092646695673,
        -0.009699399583041668,
        -0.002514604013413191,
        0.005064564757049084,
        0.018284006044268608,
        0.005606777034699917,
        -0.0044800820760428905,
        0.009764302521944046,
        -0.009085980243980885,
        0.008494921959936619,
        0.0006475340924225748,
        -0.007643502671271563,
        0.008422628045082092,
        0.01608669012784958,
        0.006973529700189829,
        -0.008992253802716732,
        -0.019795246422290802,
        0.010861153714358807,
        0.00852845050394535,
        0.0027102651074528694,
        -0.011970738880336285
      ],
      "gate_tau_start": 10.0,
      "gate_tau_end": 0.1,
      "gate_seed": 4,
      "a_path": "models/2025-12-30_16-10-47/LORA/YEARS/topk_lora_experiment/rank16-k6-sc20-Qwen_Qwen2.5-3B-Instruct-rc0.001-lr4e-07-epochs6",
      "a_lr": 4e-07,
      "a_epochs": 6,
      "loss_type": "QUESTION_LETTER_ANSWER",
      "skip_split": 4,
      "forget_accs": {
        "data/dates-years-trimmed/split_0.jsonl": {
          "0": 0.6708860759493671
        },
        "data/dates-years-trimmed/split_1.jsonl": {
          "0": 0.7088607594936709
        },
        "data/dates-years-trimmed/split_2.jsonl": {
          "0": 0.689873417721519
        },
        "data/dates-years-trimmed/split_3.jsonl": {
          "0": 0.7151898734177216
        },
        "data/dates-years-trimmed/split_4.jsonl": {
          "0": 0.7006369426751592
        }
      },
      "forget_accs_calibrated": {
        "data/dates-years-trimmed/split_0.jsonl": {
          "0": 0.6645569801330566
        },
        "data/dates-years-trimmed/split_1.jsonl": {
          "0": 0.702531635761261
        },
        "data/dates-years-trimmed/split_2.jsonl": {
          "0": 0.689873456954956
        },
        "data/dates-years-trimmed/split_3.jsonl": {
          "0": 0.7151898741722107
        },
        "data/dates-years-trimmed/split_4.jsonl": {
          "0": 0.6815286874771118
        }
      },
      "retain_accs": {
        "data/mmlu_cats_random_trimmed/mmlu_health.jsonl": {
          "0": 0.7197452229299363
        },
        "data/mmlu_cats_random_trimmed/mmlu_history.jsonl": {
          "0": 0.7898089171974523
        },
        "data/mmlu_cats_random_trimmed/mmlu_law.jsonl": {
          "0": 0.5031847133757962
        },
        "data/mmlu_cats_random_trimmed/mmlu_philosophy.jsonl": {
          "0": 0.5732484076433121
        },
        "data/mmlu_cats_random_trimmed/mmlu_social sciences.jsonl": {
          "0": 0.7133757961783439
        }
      },
      "retain_accs_calibrated": {
        "data/mmlu_cats_random_trimmed/mmlu_health.jsonl": {
          "0": 0.7452229261398315
        },
        "data/mmlu_cats_random_trimmed/mmlu_history.jsonl": {
          "0": 0.802547812461853
        },
        "data/mmlu_cats_random_trimmed/mmlu_law.jsonl": {
          "0": 0.5031847357749939
        },
        "data/mmlu_cats_random_trimmed/mmlu_philosophy.jsonl": {
          "0": 0.5541401505470276
        },
        "data/mmlu_cats_random_trimmed/mmlu_social sciences.jsonl": {
          "0": 0.7515923976898193
        }
      },
      "retain_accs_5_shot": {},
      "retain_accs_5_shot_calibrated": {}
    },
    {
      "type": "B",
      "path": "models/2025-12-30_16-10-47/fted/LORA/YEARS/topk_lora_experiment/rank16-k18-sc20-Qwen_Qwen2.5-3B-Instruct-rc0.001-lr4e-07-epochs6/topk_lora_experiment/LossType.QUESTION_LETTER_ANSWER/ft-skip_split4/lr1e-06-epoch2-epoch2",
      "timestamp": "2025-12-30T18:25:57.765821+00:00",
      "run_name": "2025-12-30_16-10-47",
      "method": "LORA",
      "dataset": "YEARS",
      "project": "topk_lora_experiment",
      "model_id": "Qwen/Qwen2.5-3B-Instruct",
      "lr": 1e-06,
      "epochs": 2,
      "retain_coeff": 0.001,
      "lora_rank": 16,
      "steering_coeff": 20,
      "lora_layer_budget_k": 18,
      "selected_blocks": [
        19,
        28,
        13,
        4,
        8,
        32,
        5,
        22,
        33,
        24,
        27,
        29,
        20,
        18,
        10,
        34,
        15,
        25
      ],
      "final_gate_scores": [
        -0.019505245611071587,
        -0.0006054528057575226,
        -0.0033960219006985426,
        -0.003197832964360714,
        0.013436204753816128,
        0.009931203909218311,
        -0.013681450858712196,
        -0.0018512606620788574,
        0.011702020652592182,
        -0.0066699255257844925,
        0.0038559262175112963,
        -0.006804247852414846,
        -0.0028729941695928574,
        0.013557206839323044,
        -0.003376457840204239,
        0.0007657092646695673,
        -0.009699399583041668,
        -0.002514604013413191,
        0.005064564757049084,
        0.018284006044268608,
        0.005606777034699917,
        -0.0044800820760428905,
        0.009764302521944046,
        -0.009085980243980885,
        0.008494921959936619,
        0.0006475340924225748,
        -0.007643502671271563,
        0.008422628045082092,
        0.01608669012784958,
        0.006973529700189829,
        -0.008992253802716732,
        -0.019795246422290802,
        0.010861153714358807,
        0.00852845050394535,
        0.0027102651074528694,
        -0.011970738880336285
      ],
      "gate_tau_start": 10.0,
      "gate_tau_end": 0.1,
      "gate_seed": 4,
      "a_path": "models/2025-12-30_16-10-47/LORA/YEARS/topk_lora_experiment/rank16-k18-sc20-Qwen_Qwen2.5-3B-Instruct-rc0.001-lr4e-07-epochs6",
      "a_lr": 4e-07,
      "a_epochs": 6,
      "loss_type": "QUESTION_LETTER_ANSWER",
      "skip_split": 4,
      "forget_accs": {
        "data/dates-years-trimmed/split_0.jsonl": {
          "0": 0.6708860759493671
        },
        "data/dates-years-trimmed/split_1.jsonl": {
          "0": 0.7088607594936709
        },
        "data/dates-years-trimmed/split_2.jsonl": {
          "0": 0.7025316455696202
        },
        "data/dates-years-trimmed/split_3.jsonl": {
          "0": 0.7088607594936709
        },
        "data/dates-years-trimmed/split_4.jsonl": {
          "0": 0.6878980891719745
        }
      },
      "forget_accs_calibrated": {
        "data/dates-years-trimmed/split_0.jsonl": {
          "0": 0.6645569801330566
        },
        "data/dates-years-trimmed/split_1.jsonl": {
          "0": 0.702531635761261
        },
        "data/dates-years-trimmed/split_2.jsonl": {
          "0": 0.6835443377494812
        },
        "data/dates-years-trimmed/split_3.jsonl": {
          "0": 0.7151898741722107
        },
        "data/dates-years-trimmed/split_4.jsonl": {
          "0": 0.6815286874771118
        }
      },
      "retain_accs": {
        "data/mmlu_cats_random_trimmed/mmlu_health.jsonl": {
          "0": 0.7197452229299363
        },
        "data/mmlu_cats_random_trimmed/mmlu_history.jsonl": {
          "0": 0.7961783439490446
        },
        "data/mmlu_cats_random_trimmed/mmlu_law.jsonl": {
          "0": 0.49044585987261147
        },
        "data/mmlu_cats_random_trimmed/mmlu_philosophy.jsonl": {
          "0": 0.5668789808917197
        },
        "data/mmlu_cats_random_trimmed/mmlu_social sciences.jsonl": {
          "0": 0.7197452229299363
        }
      },
      "retain_accs_calibrated": {
        "data/mmlu_cats_random_trimmed/mmlu_health.jsonl": {
          "0": 0.7452229261398315
        },
        "data/mmlu_cats_random_trimmed/mmlu_history.jsonl": {
          "0": 0.802547812461853
        },
        "data/mmlu_cats_random_trimmed/mmlu_law.jsonl": {
          "0": 0.5095541477203369
        },
        "data/mmlu_cats_random_trimmed/mmlu_philosophy.jsonl": {
          "0": 0.5541401505470276
        },
        "data/mmlu_cats_random_trimmed/mmlu_social sciences.jsonl": {
          "0": 0.7579618096351624
        }
      },
      "retain_accs_5_shot": {},
      "retain_accs_5_shot_calibrated": {}
    },
    {
      "type": "B",
      "path": "models/2025-12-30_16-10-47/fted/LORA/YEARS/topk_lora_experiment/rank16-k12-sc20-Qwen_Qwen2.5-3B-Instruct-rc0.001-lr4e-07-epochs6/topk_lora_experiment/LossType.QUESTION_LETTER_ANSWER/ft-skip_split4/lr1e-06-epoch2-epoch2",
      "timestamp": "2025-12-30T18:59:43.104033+00:00",
      "run_name": "2025-12-30_16-10-47",
      "method": "LORA",
      "dataset": "YEARS",
      "project": "topk_lora_experiment",
      "model_id": "Qwen/Qwen2.5-3B-Instruct",
      "lr": 1e-06,
      "epochs": 2,
      "retain_coeff": 0.001,
      "lora_rank": 16,
      "steering_coeff": 20,
      "lora_layer_budget_k": 12,
      "selected_blocks": [
        19,
        28,
        13,
        4,
        8,
        32,
        5,
        22,
        33,
        24,
        27,
        29
      ],
      "final_gate_scores": [
        -0.019505245611071587,
        -0.0006054528057575226,
        -0.0033960219006985426,
        -0.003197832964360714,
        0.013436204753816128,
        0.009931203909218311,
        -0.013681450858712196,
        -0.0018512606620788574,
        0.011702020652592182,
        -0.0066699255257844925,
        0.0038559262175112963,
        -0.006804247852414846,
        -0.0028729941695928574,
        0.013557206839323044,
        -0.003376457840204239,
        0.0007657092646695673,
        -0.009699399583041668,
        -0.002514604013413191,
        0.005064564757049084,
        0.018284006044268608,
        0.005606777034699917,
        -0.0044800820760428905,
        0.009764302521944046,
        -0.009085980243980885,
        0.008494921959936619,
        0.0006475340924225748,
        -0.007643502671271563,
        0.008422628045082092,
        0.01608669012784958,
        0.006973529700189829,
        -0.008992253802716732,
        -0.019795246422290802,
        0.010861153714358807,
        0.00852845050394535,
        0.0027102651074528694,
        -0.011970738880336285
      ],
      "gate_tau_start": 10.0,
      "gate_tau_end": 0.1,
      "gate_seed": 4,
      "a_path": "models/2025-12-30_16-10-47/LORA/YEARS/topk_lora_experiment/rank16-k12-sc20-Qwen_Qwen2.5-3B-Instruct-rc0.001-lr4e-07-epochs6",
      "a_lr": 4e-07,
      "a_epochs": 6,
      "loss_type": "QUESTION_LETTER_ANSWER",
      "skip_split": 4,
      "forget_accs": {
        "data/dates-years-trimmed/split_0.jsonl": {
          "0": 0.6582278481012658
        },
        "data/dates-years-trimmed/split_1.jsonl": {
          "0": 0.7025316455696202
        },
        "data/dates-years-trimmed/split_2.jsonl": {
          "0": 0.689873417721519
        },
        "data/dates-years-trimmed/split_3.jsonl": {
          "0": 0.7151898734177216
        },
        "data/dates-years-trimmed/split_4.jsonl": {
          "0": 0.6878980891719745
        }
      },
      "forget_accs_calibrated": {
        "data/dates-years-trimmed/split_0.jsonl": {
          "0": 0.6582278609275818
        },
        "data/dates-years-trimmed/split_1.jsonl": {
          "0": 0.7088607549667358
        },
        "data/dates-years-trimmed/split_2.jsonl": {
          "0": 0.6835443377494812
        },
        "data/dates-years-trimmed/split_3.jsonl": {
          "0": 0.7088607549667358
        },
        "data/dates-years-trimmed/split_4.jsonl": {
          "0": 0.6815286874771118
        }
      },
      "retain_accs": {
        "data/mmlu_cats_random_trimmed/mmlu_health.jsonl": {
          "0": 0.7197452229299363
        },
        "data/mmlu_cats_random_trimmed/mmlu_history.jsonl": {
          "0": 0.7961783439490446
        },
        "data/mmlu_cats_random_trimmed/mmlu_law.jsonl": {
          "0": 0.5031847133757962
        },
        "data/mmlu_cats_random_trimmed/mmlu_philosophy.jsonl": {
          "0": 0.5796178343949044
        },
        "data/mmlu_cats_random_trimmed/mmlu_social sciences.jsonl": {
          "0": 0.7133757961783439
        }
      },
      "retain_accs_calibrated": {
        "data/mmlu_cats_random_trimmed/mmlu_health.jsonl": {
          "0": 0.7452229261398315
        },
        "data/mmlu_cats_random_trimmed/mmlu_history.jsonl": {
          "0": 0.802547812461853
        },
        "data/mmlu_cats_random_trimmed/mmlu_law.jsonl": {
          "0": 0.5031847357749939
        },
        "data/mmlu_cats_random_trimmed/mmlu_philosophy.jsonl": {
          "0": 0.5477707386016846
        },
        "data/mmlu_cats_random_trimmed/mmlu_social sciences.jsonl": {
          "0": 0.7579618096351624
        }
      },
      "retain_accs_5_shot": {},
      "retain_accs_5_shot_calibrated": {}
    },
    {
      "type": "B",
      "path": "models/2025-12-30_16-10-47/fted/LORA/YEARS/topk_lora_experiment/rank16-k24-sc20-Qwen_Qwen2.5-3B-Instruct-rc0.001-lr4e-07-epochs6/topk_lora_experiment/LossType.QUESTION_LETTER_ANSWER/ft-skip_split4/lr1e-06-epoch2-epoch2",
      "timestamp": "2025-12-30T19:01:07.718015+00:00",
      "run_name": "2025-12-30_16-10-47",
      "method": "LORA",
      "dataset": "YEARS",
      "project": "topk_lora_experiment",
      "model_id": "Qwen/Qwen2.5-3B-Instruct",
      "lr": 1e-06,
      "epochs": 2,
      "retain_coeff": 0.001,
      "lora_rank": 16,
      "steering_coeff": 20,
      "lora_layer_budget_k": 24,
      "selected_blocks": [
        19,
        28,
        13,
        4,
        8,
        32,
        5,
        22,
        33,
        24,
        27,
        29,
        20,
        18,
        10,
        34,
        15,
        25,
        1,
        7,
        17,
        12,
        3,
        14
      ],
      "final_gate_scores": [
        -0.019505245611071587,
        -0.0006054528057575226,
        -0.0033960219006985426,
        -0.003197832964360714,
        0.013436204753816128,
        0.009931203909218311,
        -0.013681450858712196,
        -0.0018512606620788574,
        0.011702020652592182,
        -0.0066699255257844925,
        0.0038559262175112963,
        -0.006804247852414846,
        -0.0028729941695928574,
        0.013557206839323044,
        -0.003376457840204239,
        0.0007657092646695673,
        -0.009699399583041668,
        -0.002514604013413191,
        0.005064564757049084,
        0.018284006044268608,
        0.005606777034699917,
        -0.0044800820760428905,
        0.009764302521944046,
        -0.009085980243980885,
        0.008494921959936619,
        0.0006475340924225748,
        -0.007643502671271563,
        0.008422628045082092,
        0.01608669012784958,
        0.006973529700189829,
        -0.008992253802716732,
        -0.019795246422290802,
        0.010861153714358807,
        0.00852845050394535,
        0.0027102651074528694,
        -0.011970738880336285
      ],
      "gate_tau_start": 10.0,
      "gate_tau_end": 0.1,
      "gate_seed": 4,
      "a_path": "models/2025-12-30_16-10-47/LORA/YEARS/topk_lora_experiment/rank16-k24-sc20-Qwen_Qwen2.5-3B-Instruct-rc0.001-lr4e-07-epochs6",
      "a_lr": 4e-07,
      "a_epochs": 6,
      "loss_type": "QUESTION_LETTER_ANSWER",
      "skip_split": 4,
      "forget_accs": {
        "data/dates-years-trimmed/split_0.jsonl": {
          "0": 0.6582278481012658
        },
        "data/dates-years-trimmed/split_1.jsonl": {
          "0": 0.7025316455696202
        },
        "data/dates-years-trimmed/split_2.jsonl": {
          "0": 0.7025316455696202
        },
        "data/dates-years-trimmed/split_3.jsonl": {
          "0": 0.7088607594936709
        },
        "data/dates-years-trimmed/split_4.jsonl": {
          "0": 0.7133757961783439
        }
      },
      "forget_accs_calibrated": {
        "data/dates-years-trimmed/split_0.jsonl": {
          "0": 0.6835443377494812
        },
        "data/dates-years-trimmed/split_1.jsonl": {
          "0": 0.7151898741722107
        },
        "data/dates-years-trimmed/split_2.jsonl": {
          "0": 0.689873456954956
        },
        "data/dates-years-trimmed/split_3.jsonl": {
          "0": 0.7088607549667358
        },
        "data/dates-years-trimmed/split_4.jsonl": {
          "0": 0.6815286874771118
        }
      },
      "retain_accs": {
        "data/mmlu_cats_random_trimmed/mmlu_health.jsonl": {
          "0": 0.7197452229299363
        },
        "data/mmlu_cats_random_trimmed/mmlu_history.jsonl": {
          "0": 0.7898089171974523
        },
        "data/mmlu_cats_random_trimmed/mmlu_law.jsonl": {
          "0": 0.5095541401273885
        },
        "data/mmlu_cats_random_trimmed/mmlu_philosophy.jsonl": {
          "0": 0.5796178343949044
        },
        "data/mmlu_cats_random_trimmed/mmlu_social sciences.jsonl": {
          "0": 0.7133757961783439
        }
      },
      "retain_accs_calibrated": {
        "data/mmlu_cats_random_trimmed/mmlu_health.jsonl": {
          "0": 0.7452229261398315
        },
        "data/mmlu_cats_random_trimmed/mmlu_history.jsonl": {
          "0": 0.7961783409118652
        },
        "data/mmlu_cats_random_trimmed/mmlu_law.jsonl": {
          "0": 0.5095541477203369
        },
        "data/mmlu_cats_random_trimmed/mmlu_philosophy.jsonl": {
          "0": 0.5350318551063538
        },
        "data/mmlu_cats_random_trimmed/mmlu_social sciences.jsonl": {
          "0": 0.7579618096351624
        }
      },
      "retain_accs_5_shot": {},
      "retain_accs_5_shot_calibrated": {}
    }
  ],
  "C": [
    {
      "type": "C",
      "path": "models/2025-12-30_16-10-47/baseline_rtt/YEARS/Qwen_Qwen2.5-3B-Instruct/QUESTION_LETTER_ANSWER/skip_split4/lr1e-06-epoch2-epoch2",
      "timestamp": "2025-12-30T20:12:43.162151+00:00",
      "run_name": "2025-12-30_16-10-47",
      "dataset": "YEARS",
      "model_id": "Qwen/Qwen2.5-3B-Instruct",
      "loss_type": "QUESTION_LETTER_ANSWER",
      "lr": 1e-06,
      "epochs": 2,
      "skip_split": 4,
      "forget_accs": {
        "data/dates-years-trimmed/split_0.jsonl": {
          "0": 0.6772151898734177
        },
        "data/dates-years-trimmed/split_1.jsonl": {
          "0": 0.7088607594936709
        },
        "data/dates-years-trimmed/split_2.jsonl": {
          "0": 0.6962025316455697
        },
        "data/dates-years-trimmed/split_3.jsonl": {
          "0": 0.740506329113924
        },
        "data/dates-years-trimmed/split_4.jsonl": {
          "0": 0.6878980891719745
        }
      },
      "forget_accs_calibrated": {
        "data/dates-years-trimmed/split_0.jsonl": {
          "0": 0.6708860993385315
        },
        "data/dates-years-trimmed/split_1.jsonl": {
          "0": 0.7278481125831604
        },
        "data/dates-years-trimmed/split_2.jsonl": {
          "0": 0.6835443377494812
        },
        "data/dates-years-trimmed/split_3.jsonl": {
          "0": 0.746835470199585
        },
        "data/dates-years-trimmed/split_4.jsonl": {
          "0": 0.6878980994224548
        }
      },
      "retain_accs": {
        "data/mmlu_cats_random_trimmed/mmlu_health.jsonl": {
          "0": 0.732484076433121
        },
        "data/mmlu_cats_random_trimmed/mmlu_history.jsonl": {
          "0": 0.7898089171974523
        },
        "data/mmlu_cats_random_trimmed/mmlu_law.jsonl": {
          "0": 0.4968152866242038
        },
        "data/mmlu_cats_random_trimmed/mmlu_philosophy.jsonl": {
          "0": 0.5796178343949044
        },
        "data/mmlu_cats_random_trimmed/mmlu_social sciences.jsonl": {
          "0": 0.7388535031847133
        }
      },
      "retain_accs_calibrated": {
        "data/mmlu_cats_random_trimmed/mmlu_health.jsonl": {
          "0": 0.7452229261398315
        },
        "data/mmlu_cats_random_trimmed/mmlu_history.jsonl": {
          "0": 0.808917224407196
        },
        "data/mmlu_cats_random_trimmed/mmlu_law.jsonl": {
          "0": 0.522292971611023
        },
        "data/mmlu_cats_random_trimmed/mmlu_philosophy.jsonl": {
          "0": 0.5732483863830566
        },
        "data/mmlu_cats_random_trimmed/mmlu_social sciences.jsonl": {
          "0": 0.7643312215805054
        }
      },
      "retain_accs_5_shot": {},
      "retain_accs_5_shot_calibrated": {}
    }
  ],
  "Baseline": [
    {
      "type": "Baseline",
      "model_id": "Qwen/Qwen2.5-3B-Instruct",
      "dataset": "YEARS",
      "forget_accs": {
        "data/dates-years-trimmed/split_0.jsonl": {
          "0": 0.6329113924050633
        },
        "data/dates-years-trimmed/split_1.jsonl": {
          "0": 0.6012658227848101
        },
        "data/dates-years-trimmed/split_2.jsonl": {
          "0": 0.6329113924050633
        },
        "data/dates-years-trimmed/split_3.jsonl": {
          "0": 0.6392405063291139
        },
        "data/dates-years-trimmed/split_4.jsonl": {
          "0": 0.6878980891719745
        }
      },
      "forget_accs_calibrated": {
        "data/dates-years-trimmed/split_0.jsonl": {
          "0": 0.5822784900665283
        },
        "data/dates-years-trimmed/split_1.jsonl": {
          "0": 0.5822784900665283
        },
        "data/dates-years-trimmed/split_2.jsonl": {
          "0": 0.6139240860939026
        },
        "data/dates-years-trimmed/split_3.jsonl": {
          "0": 0.6582278609275818
        },
        "data/dates-years-trimmed/split_4.jsonl": {
          "0": 0.6815286874771118
        }
      },
      "retain_accs": {
        "data/mmlu_cats_random_trimmed/mmlu_health.jsonl": {
          "0": 0.732484076433121
        },
        "data/mmlu_cats_random_trimmed/mmlu_history.jsonl": {
          "0": 0.8152866242038217
        },
        "data/mmlu_cats_random_trimmed/mmlu_law.jsonl": {
          "0": 0.4840764331210191
        },
        "data/mmlu_cats_random_trimmed/mmlu_philosophy.jsonl": {
          "0": 0.5732484076433121
        },
        "data/mmlu_cats_random_trimmed/mmlu_social sciences.jsonl": {
          "0": 0.732484076433121
        }
      },
      "retain_accs_calibrated": {
        "data/mmlu_cats_random_trimmed/mmlu_health.jsonl": {
          "0": 0.7324841022491455
        },
        "data/mmlu_cats_random_trimmed/mmlu_history.jsonl": {
          "0": 0.8152866363525391
        },
        "data/mmlu_cats_random_trimmed/mmlu_law.jsonl": {
          "0": 0.5031847357749939
        },
        "data/mmlu_cats_random_trimmed/mmlu_philosophy.jsonl": {
          "0": 0.5286624431610107
        },
        "data/mmlu_cats_random_trimmed/mmlu_social sciences.jsonl": {
          "0": 0.7515923976898193
        }
      },
      "retain_accs_5_shot": {},
      "retain_accs_5_shot_calibrated": {}
    }
  ]
}